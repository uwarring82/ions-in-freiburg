---
description: How the 2025 Nobel Prize in Physics forced me to recalibrate my own detector
---

# \[Draft] The Bias I Carry

{% hint style="info" %}
**Author:** U. Warring\
**Affiliation:** Institute of Physics, University of Freiburg\
**Version:** 0.2\
**Last updated:** 2025-12-12\
**License:** CC BY-SA 4.0\
\
**Disclaimer** — _This is a personal, reflective essay written in my role as a physicist educated in the trapped-ion community. It is not an official statement of my institution, nor a verdict on any particular research group or platform. All descriptions of “communities” are deliberately abstracted patterns, not portraits of specific individuals. The purpose is to examine how tribal bias forms in science, and what it takes to correct it._
{% endhint %}

***

### Context

In October 2025, the Royal Swedish Academy of Sciences awarded the Nobel Prize in Physics jointly to John Clarke, Michel H. Devoret, and John M. Martinis

> “for the discovery of macroscopic quantum mechanical tunnelling and energy quantisation in an electric circuit”.&#x20;

The work being honored dates back to the mid-1980s. The laureates showed that a carefully engineered superconducting circuit could exhibit macroscopic quantum tunnelling and discrete energy levels: a designed electrical circuit behaving as a quantum object in its own right.

This essay is not about the technical details of those experiments. Other documents—the Nobel scientific background, original PRL papers, and modern lecture notes—do that much better.

Instead, it is about the bias I carried when I first read the 2025 announcement, and the process of correcting that bias.

***

### Why this essay matters

For me, this essay is an accountability exercise. I want my students and my children to see a version of me who can notice bias, name it publicly, and change.

For readers, I hope this functions as a case study. Most scientists recognize tribal instincts in themselves, but we rarely see someone walk through the correction process in detail. If this text works, it gives others permission—and a few tools—to do similar work.

For the field, the stakes are larger. Scientific credibility depends not only on technical rigor, but on our capacity to transcend tribal reasoning: to evaluate claims by content rather than clan, and to design systems that make such evaluation more likely. Technical expertise does not immunize us against bias. If anything, it often arms our biases with better arguments. The question is: what counter-systems do we build?

My core thesis is simple:

> Tribal bias in science rarely forms through dramatic conversion experiences. It accumulates through hundreds of small, ambiguous encounters—each individually forgettable, collectively load-bearing. Correction requires not willpower but systems: anchors that pull against tribal gravity, protocols that introduce friction between bias and action.

The three anchors that eventually pulled me back here are:

* Technical respect – Was the physics actually good?
* Institutional trust – Did the Committee make a defensible choice within its constraints?
* Moral responsibility – What am I modeling for my students and children?

The 2025 Nobel Prize exposed how weak each of these anchors had become in me, and what it took to rebuild them.

***

### 1. The Measurement

On an ordinary October afternoon in 2025, between an email about lab class procedures and a student asking why the laser would not lock, I saw the headline on my phone:

> _“Nobel Prize in Physics 2025: John Clarke, Michel H. Devoret, John M. Martinis.”_&#x20;

Before I finished reading the citation—“_for the discovery of..._ ”—a thought surfaced that had nothing to do with physics:

> _“Really? The community that already raised billions for the ‘platform of the future’ now also gets a Nobel Prize?”_

My jaw tightened. My first reaction was not admiration. It was a flash of resentment: the sense that some invisible accounting of “who has already gotten how much” had just become even more unbalanced.

I did _not_ think about Josephson junctions, macroscopic phases, or escape rates. I thought about start-ups, glossy keynotes, funding asymmetries. I thought about “our” corner of quantum information—trapped ions—where things often seemed slower, less glamorous, more conservative in promises, and somehow less rewarded.

It took a few seconds before another, quieter realization arrived: this reaction did not fit the scientist I like to imagine myself to be. I tell students to read carefully before judging. I tell my children to “check what someone actually did” before deciding whether something is fair. I had done neither. I had reacted to a _symbol_.

In that sense, the Nobel announcement acted like a sharp measurement pulse on a system I usually prefer not to observe too closely: my own pattern of tribal thinking.

This essay is my attempt to treat that moment as data. Not to defend my initial reaction, and not to replace it with a polished narrative of “how I immediately corrected myself”, but to examine:

* how that reaction formed over years,
* what changed when I actually engaged with the 1980s work,
* how I came to see the Nobel Committee’s choice differently, and
* what responsibilities follow from noticing all this.

Three anchors pulled me back: respect for the technical achievement, a more nuanced view of the institution that awarded the prize, and an uncomfortable awareness of what I am modeling when I speak in front of students and children. But before any anchor could do work, I had to understand how the bias formed.

***

### 2. The Formation

I cannot point to a single moment when the tribal map in my head formed. That is precisely the problem.

Bias does not usually announce itself with dramatic conversion experiences. It accumulates—through hundreds of small, ambiguous encounters, each individually forgettable, none individually sufficient to warrant a change in self-image. Over time, they crystallize into something solid enough that we call it “intuition”.

#### 2.1 Ion-trap socialisation

I was trained in atomic phyiscs and among ion trappers.

Technically, that meant nights spent thinking about dark counts and heating rates, about micromotion compensation and secular frequencies. It meant long discussions about systematic errors, cross-checks, Allan deviations, and what counts as “good enough” for metrological claims. The culture I absorbed valued:

* showing the noise sources, not hiding them,
* being conservative in interpretation,
* demonstrating control in clean, tightly coupled systems, and
* proving coherence with painstaking sequences rather than a single spectacular plot.

These instincts are not wrong. They made me a better experimentalist. They still do. They taught me to ask hard questions about error budgets, to be suspicious of claims that fit too neatly into a narrative, and to value slow, cumulative progress.

But there is a trap hidden inside this carefulness:

> When you are trained in one particular way of being careful, it becomes easy to mistake other ways of being careful for being careless.

I was not taught to be tribal. I was taught to be careful. Over time, unchecked, careful hardened into tribal.

#### 2.2 The accumulation

The tribal map did not appear fully formed. It was reinforced by a long sequence of encounters, which I now only remember in outline.

There were conference talks where slides advanced faster than I could parse the error analysis. There were papers where citations seemed to skip over foundational work I knew existed in trapped ions or other platforms. There were large funding announcements that felt disproportionate to the publicly verifiable results. There were hallway remarks about alternative platforms being “too slow” or “never scalable”.

Each of these encounters was ambiguous:

* The rushed slides may have summarized careful analysis that was simply not shown in full.
* The missing citation may have been an honest oversight in an overcrowded reference list.
* The funding decisions may have reflected strategic considerations I did not see.
* The irritated hallway remark may have been the product of exhaustion rather than deep contempt.

Any one of these encounters, taken seriously and charitably, could have ended in a shrug: “I do not have enough information to judge.” The problem is that I was not evaluating them in isolation. I was pattern-matching to a narrative that was already forming.

Evidence that fit the pattern—overselling, under-citing, over-funding—was filed as confirmation. Evidence that did not fit—careful work from that community, generous cross-platform credit, conservative public statements—became “exceptions”: _that_ group is serious, _that_ person is different.

This is the cognitive structure of confirmation bias: interpreting new information in ways that are partial to existing beliefs, expectations, or hypotheses. The bias does not require ill will. It only requires asymmetric weighting.

#### 2.3 Compression into symbols

Human cognition is extraordinarily good at compression. Instead of tracking hundreds of individual researchers and thousands of individual results, we form categories: “ion trappers”, “superconducting quantum engineers”, “neutral-atom people”.

The compression is efficient. It saves cognitive effort. But it comes at a cost.

In my case, an entire quantum-engineering community collapsed into a few symbolic figures. A recognizable name on a program or a familiar logo on a slide stood in for a whole platform and a whole style of physics. Work I had not read became “probably overstated”. People I had never met became “one of them”.

Social identity theory predicts this dynamic. Once we categorize people into in-groups and out-groups, our self-concept becomes tied to our group’s status. The successes of an out-group feel like threats; their recognition feels undeserved. The same mechanism drives intergroup behaviour in minimal group experiments where categorization is nearly meaningless. It works just as well when the categories are “our platform” and “their platform”.

Another well-known pattern, the fundamental attribution error, did the rest. When “they” made ambitious claims, I attributed it to character: “they are reckless”, “they are hyping”. When “we” communicated cautiously, I explained it by context: “we face higher scrutiny”, “we are held to stricter standards”. Similar behavior, different explanations, based solely on group membership.

The compression saved cognitive effort. It also destroyed nuance.

#### 2.4 The feedback loop

Once the tribal map existed, a feedback loop closed around it.

When I read a paper from “our” side, I began with a presumption of good faith. Limitations were assumed to be acknowledged, even if not on the first page. Caveats were assumed to be implicit. When I read a paper from “their” side, I began with active suspicion. I searched for the overstated claim, the missing control, the error bar that seemed too small.

In peer review, this pattern would have been measurable. I do not have statistics, but if someone had tracked my referee reports by platform, I suspect a correlation would appear: harsher language, more requested revisions, and more frequent rejections when manuscripts came from the out-group. I believed I was enforcing uniform rigor. In practice, I was enforcing rigor selectively. A few years ago, I installed a scaffolding for my reviews to mitigate this bias.

Group discussions amplified the pattern. Skeptical remarks about “their” platform were met with knowing nods. Each shared dismissal made the dismissal feel more justified. Cass Sunstein’s work on group polarization predicts exactly this: like-minded groups, discussing issues they already agree on, tend to move toward more extreme positions rather than moderation.

By the time the Nobel Committee announced Clarke, Devoret, and Martinis, my tribal map of the quantum-engineering world was complete enough that I did not feel I needed to read the citation carefully. I already “knew” what I thought.

The announcement simply triggered the map.

***

### 3. Anchor 1 — Technical Respect

Technical respect is supposed to be my epistemological foundation. Whatever my preferences or loyalties, I like to believe that careful, difficult physics receives my respect when I actually look at it.

After my initial reaction to the Nobel, I did what I should have done immediately: I started reading.

#### 3.1 The moment that cracked certainty

The first crack came not from a paper, but from a lecture.

A colleague gave a seminar on the 2025 Nobel, focusing on the early experiments rather than the modern quantum computing ecosystem. I went in with residual resentment, expecting a familiar story: highlight the 1980s work quickly, then pivot to present-day chips, gate counts, and industrial roadmaps.

Instead, I found myself looking at a grainy photograph from 1985: a dilution refrigerator in a university basement, surrounded by hand-labeled electronics boxes, coils of cable, improvised shielding. No corporate logos, no branding, no sleek cleanroom shots. Just three people—professor, postdoc, student—trying to push a theoretical question to the limit.

The talk patiently reconstructed the logic: the Caldeira-Leggett prediction that a macroscopic collective coordinate could retain quantum behavior if its coupling to the environment were sufficiently small; the idea that the phase difference across a Josephson junction could serve as such a coordinate; the challenge of making an actual circuit that, when cooled and filtered, behaves like a particle in a metastable potential.

Something in me shifted. Not dramatically—I did not convert into an enthusiastic fan of superconducting qubits overnight. But the industrial wrapper I had projected onto the work peeled away. Underneath, there was a familiar story: a hard conceptual question, a decade of theory, and an experiment that demanded meticulous noise engineering.

#### 3.2 What they actually achieved

The key conceptual question was straightforward to state and hard to answer:

> Can a macroscopic degree of freedom—describing the collective behavior of a huge number of electrons—show unmistakably quantum behavior, if you control its environment well enough?

The Caldeira-Leggett framework had quantified how environmental dissipation suppresses quantum tunnelling and decoherence. It predicted that for sufficiently small damping, the escape rate of a system from a potential well would saturate at low temperatures: instead of going to zero as thermal activation shuts down, it would approach a constant “quantum tunnelling floor”.

The Berkeley experiments built a device where the relevant coordinate was the superconducting phase across a Josephson junction, and the potential was engineerable by circuit parameters. The task was to cool and isolate this effective coordinate enough that the predicted macroscopic quantum tunnelling could actually be observed.

That required several layers of experimental ingenuity:

* Impedance engineering. The environment seen by the junction at relevant frequencies had to effectively present a very high impedance, suppressing dissipation. This meant carefully designed transmission lines, on-chip and off-chip filtering, and a detailed understanding of parasitic modes in the wiring.
* Filtering and shielding. High-frequency noise from room-temperature electronics and thermal radiation had to be absorbed and thermalized in stages. Copper-powder filters, attenuators at different temperature stages, and nested shields all played roles.
* Measurement without destruction. The readout scheme had to detect whether the phase had escaped the well without itself dumping energy into the system in a way that dominated the escape dynamics.

The measurements then tested the escape rate as a function of temperature. At higher temperatures, the escape was consistent with thermal activation: the rate decreased as the bath cooled. Below a crossover temperature, the rate stopped decreasing and approached a plateau consistent with the quantum tunnelling prediction, with no free fitting parameters.

A second set of experiments used microwave spectroscopy to probe energy levels in the effective potential. When the applied microwave frequency matched the spacing between quantized levels, the escape rate changed in a way that revealed discrete structure: the circuit behaved like an artificial atom, with engineered energy spacings determined by capacitances and inductances.

None of this is exotic by today’s standards. For those of us who teach circuit QED and transmon physics, the language has become standard. But in 1985, this was a conceptual leap: circuits were not just passive elements connecting quantum systems. They _were_ the quantum systems.

#### 3.3 The lineage I had ignored

As I followed the references forward, a lineage emerged that I had taken for granted.

The techniques of impedance engineering, filtering, and environmental modeling that made the 1985 experiments possible are now embedded in nearly every lab that works with fragile quantum systems: trapped ions, superconducting qubits, Rydberg atoms, NV centers.

In circuit quantum electrodynamics, the same design philosophy underlies the coupling of artificial atoms to microwave resonators and the protection of qubit coherence. The transmon qubit design solved specific noise sensitivities while preserving and refining the idea of circuits as quantum objects. The filtering and wiring strategies in modern dilution fridges are direct descendants of those early efforts.

Even in ion trapping, we routinely rely on microwave and DC filtering chains, ground-reference strategies, and environmental modeling that share DNA with the approaches pioneered in the superconducting community. I had simply never asked where many of these techniques came from. I implicitly coded them as “ours”.

The half-life of these methods is measured in decades. That is one reasonable measure of scientific impact: how long techniques remain in active use and how widely they are re-applied.

#### 3.4 The first anchor pulls

All of this left me with an uncomfortable conclusion:

> I had dismissed the 1980s superconducting work without ever looking at it with the same care I demand from my students.

My technical respect—normally something I would cite as a core value—had been conditional. It applied fully inside my tribe. It applied selectively outside.

Once that was clear, one anchor had started to pull: whatever I thought about later industrial developments, the foundational physics recognized by the Nobel Committee was neither trivial nor hyped. **It was hard, beautiful work. Congratulations to everyone who contributed to this culmination of success.**

That realization led naturally to the next question: if the physics was this good, what about the institution that chose to recognize it?

***

### 4. Anchor 2 — Institutional Trust

Understanding the Nobel Committee’s decision required something I had not initially granted them: the benefit of the doubt.

#### 4.1 The impossible job

The Nobel Committee faces a genuinely impossible task. For the 2025 prize, they had to:

* assess decades of intertwined contributions, from theoretical predictions in the 1980s to experimental breakthroughs and platform development across multiple communities,
* compress a complex, collaborative history into exactly three names, due to the statutory limit,
* distinguish between foundational discoveries and later applications,
* decide how much weight to give different platforms and schools, and
* do all of this under conditions of incomplete information, with decisions that will be scrutinized indefinitely.

My initial reaction implicitly assumed that, in this case, they had simply capitulated to hype: selected the platform with the largest current industrial profile and retrofitted a foundational story.

After engaging with the 1980s work, that assumption became harder to justify. To maintain it, I would have to claim either that the Committee was ignorant of the field’s history or that it knowingly ignored that history in favor of geopolitical or economic considerations.

That is a strong accusation. It demands evidence. I had none.

#### 4.2 What the citation actually says

The citation itself is concise:

> “for the discovery of macroscopic quantum mechanical tunnelling and energy quantisation in an electric circuit”.&#x20;

The choice of words is deliberate:

* “Discovery” – The focus is on revealing a new phenomenon or regime, not on building a device for a specific application.
* “Macroscopic quantum mechanical” – This is framed as a fundamental physics question: can quantum mechanics manifest in suitably engineered macroscopic variables?
* “Electric circuit” – The system is a designed artifact, not a naturally occurring atom or molecule. The move from “nature-given quantum system” to “engineered quantum system” is the conceptual pivot.

Equally important are the omissions. The citation does _not_ mention:

* qubits,
* quantum computers,
* specific architectures like circuit QED,
* any work from the 2000s and 2010s on coherent control, error correction, or scaling.

Viewed in this way, the Committee anchored the prize firmly in the mid-1980s. They chose to recognize the moment when an electric circuit first earned the status of a legitimate quantum system in its own right, in close dialogue with the Caldeira-Leggett framework that had previously been recognized in part through Anthony Leggett’s 2003 Nobel.

One can certainly debate whether 1985 is the right place to draw that line. Yasunobu Nakamura’s 1999 demonstration of coherent oscillations in a superconducting charge qubit, for example, is also an obvious milestone, and many would argue it deserved recognition. Other contributors to flux qubits and circuit QED could also reasonably appear in alternative histories.

But “debatable” is not the same as “obviously wrong”. My initial reading—“they validated the hype platform”—had ignored the internal logic of the citation entirely.

#### 4.3 Inevitable omissions

Within the three-person limit, omissions are inevitable. The 2025 choice effectively draws a boundary around “proof of macroscopic quantum behavior in circuits” and treats later developments in coherent control, architecture, and scaling as downstream.

Is that choice painful for those whose work sits just outside the boundary? Yes. Is it structurally biased toward early movers in well-positioned institutions? Almost certainly. Does it reflect deeper geographic and institutional asymmetries in who gets to do path-defining foundational work? Probably.

But it is not uniquely pathological. The Nobel system has always separated theoretical predictions and experimental confirmations across different prizes (as with Josephson’s 1973 award for the theoretical prediction of tunnelling supercurrents, followed decades later by experimental recognitions). Platform diversity has also been recognized explicitly, as in the 2012 Nobel for Haroche and Wineland, which balanced cavity QED and trapped ions.

Here, the Committee seems to have chosen to honor foundational physics in one platform, with some implicit expectation that complementary platforms had already been recognized (trapped ions in 2012) or might be recognized in other ways.

One can still argue for alternative distributions. But that is a different argument from claiming that the Committee simply chased current industrial narratives.

#### 4.4 What institutional trust requires

Institutional trust does not mean blind acceptance. The Nobel system has structural flaws:

* it over-compresses collaborative science into a small number of names,
* it tends to reflect existing power structures,
* and its long time lag can mismatch scientific and societal timing.

Recognizing these flaws is compatible with granting that committees can, within constraints, act conscientiously.

My own institutional distrust in October 2025 was easier to maintain when I had not engaged with the underlying physics. Once I had done so, the cognitive mismatch became sharp:

* The experimental work looked solid and foundational.
* The Committee’s framing, while debatable, was coherent and focused on discovery rather than hype.
* My strongest remaining argument was not technical but tribal.

The second anchor, then, was not “the Nobel Committee is always right”. It was something weaker and more honest:

> Assume careful reasoning unless you have evidence to the contrary. Disagree with the choice if you must—but do not explain it by bad faith when you have not checked.

That realization pushed me toward the third anchor: responsibility.

***

### 5. Anchor 3 — Responsibility

By the time technical respect and institutional trust had partially corrected my view of the 2025 prize, another question had become unavoidable:

> What am I teaching, explicitly and implicitly, when I talk about such things in front of students and my own children?

#### 5.1 Students are always watching

There are lab meetings and journal clubs I can no longer reconstruct in detail, but I remember the pattern.

A student would present a paper from “our” platform. My opening questions would be technical, sometimes sharp, but framed within an atmosphere of shared trust: we assume the authors are trying to do good work; we are collectively trying to probe limitations.

On other days, a student would present a paper from “the other side”. My questions, in those cases, carried a subtly different edge. Before the first plot had been fully discussed, I might probe the choice of metric, the absence of a particular benchmark, or the way an abstract was worded.

Each individual question was defensible. Many of them were the kinds of questions we _should_ ask in all cases. The problem was not the content. It was the asymmetry.

Students learn more from tone and pattern than from formal statements. Whatever I might have said about “evaluating science on its merits”, my behavior taught a different lesson:

* work from our tribe is presumed careful until proven otherwise;
* work from their tribe is presumed inflated until proven otherwise.

The more senior I became, the more my questions could shape the room. A skeptical remark from me could license a whole group to treat a platform dismissively. In that sense, I was not only carrying bias. I was transmitting it.

#### 5.2 The question my children might ask

When I imagine explaining my initial reaction to my children, the logic unravels quickly.

> Child: “Why were you upset when those scientists won the prize?”

> Me: “Because I thought other people deserved it more.”

> Child: “Did you read what they actually did?”

> Me: “Not really, not at first. I saw their names and… reacted.”

> Child: “Because of what?”

> Me: “Because they are part of a community that already has a lot of money and attention, and I felt that wasn’t fair.”

> Child: “But you always tell me to judge people by what they do, not where they’re from.”

> Me: “Yes. This time I didn’t.”

I can add layers of complexity about credit, structural inequalities, and the distribution of resources among platforms. Those are real issues. But at the core, my initial reaction did not rest on this analysis. It rested on _who_ I associated with the prize, not _what_ they had done.

Children are very good at detecting such inconsistencies. They do not need to know the details of superconducting circuits to notice when the principle “judge by content” is not being applied.

#### 5.3 What I actually owe

Once all of this was clear, the third anchor—the moral one—began to pull.

There are at least four responsibilities I cannot outsource to institutions:

1.  Model intellectual honesty.

    Not the performance of always being right, but the more uncomfortable practice of saying, in front of others: _“I was wrong about this. Here is how I know. Here is what I am changing.”_ Private correction teaches no one. Public correction teaches that changing one’s mind is part of the job.
2.  Model bias-correction protocols.

    It is not enough to exhort students to “avoid bias”. They need to see concrete methods: how to notice an asymmetric reaction, how to check whether it tracks content or source, how to adjust reading and questioning habits accordingly.
3.  Model humility about expertise.

    Technical expertise in one platform or subfield does not grant global authority. It certainly does not immunize against motivated reasoning. Admitting the specific limits and distortions of one’s perspective is a form of accuracy, not weakness.
4.  Model generosity as default.

    This does not mean naivety. It means starting from the assumption that colleagues in other communities also care about correctness, and that differences in language, emphasis, or style often reflect different local constraints rather than moral failings.

Philosophers writing about intellectual humility describe it as a disposition to recognize and respond appropriately to one’s cognitive limitations. In this context, the limitation is not a lack of technical knowledge, but a tribal weighting of evidence.

#### 5.4 Generational stakes

The stakes are generational.

My students will inherit more than the equipment and the analysis scripts. They will inherit:

* the credit practices I model in talks and papers,
* the standards I apply in peer review,
* the way I speak about competing approaches in informal settings.

My children will inherit a scientific culture that they may or may not choose to engage with. Whether that culture is capable of collaboration across platform boundaries, whether it commands public trust, and whether it pairs expertise with humility rather than tribal armor—these are not abstractions. They shape which problems can be tackled and by whom.

Individual correction is necessary. It is also not sufficient. The bias machine will not stop running because one person writes an essay. The question then becomes: what systems can we put in place to make bias-correction more likely, more systematic, and more robust than a single person’s resolve?

***

### 6. Protocols — Building Better Systems

I do not trust my willpower.

I will likely fail at this again: react too quickly to a headline, ask an unfair question in a seminar, give too much weight to a rumor that fits my tribal expectations. Knowing this, I need more than good intentions. I need protocols—structures that introduce friction between bias and action.

#### 6.1 Individual protocols

These are small, personal systems I am trying to adopt.

**(1) Notice before acting.**

When I encounter a result from a community I have historically distrusted, I try to insert one pause:

* Notice the immediate emotional reaction.
* Ask explicitly: “Is this reaction about what is written, or about who wrote it?”
* If the answer is “both” or “mostly the latter”, commit to reading the technical content before forming a verdict.

This does not eliminate bias. It creates a small time window in which the first anchor—technical respect—can engage.

**(2) A quarterly tribal audit.**

Every few months, I look back at the papers and preprints I have actually read carefully (not just skimmed). I ask:

* How many are from my own platform or close collaborators?
* How many are from competing platforms or communities?
* Where did I invest effort in understanding, and where did I dismiss quickly?

If the distribution is sharply skewed, I deliberately choose a handful of influential or widely discussed papers from outside my comfort zone and read them as if they were from my own group: with patience and charitable interpretation of ambiguity.

You cannot fix a bias you refuse to measure.

**(3) Credit discipline.**

In my own writing and talks, I try to be more systematic about:

* citing predecessors across platforms, not just within my own,
* acknowledging when methods or concepts we use descend from work in other communities, and
* contextualizing our results relative to others even when the comparison is uncomfortable.

This is partly about fairness. It is also about making visible the actual interdependence of platforms and techniques.

**(4) Pedagogical check.**

Before I make a critical remark about someone else’s work in front of students, I ask:

> “Would I be comfortable saying this, in this tone, if the authors were in the room—or if my children were listening?”

If the answer is no, I rephrase or remain silent until I can express the concern in a way that targets claims rather than clans. Science requires criticism. It does not require contempt.

#### 6.2 Institutional interventions

Individual protocols are fragile. They degrade under stress and time pressure. Institutions can help by embedding some of the necessary friction structurally.

A few examples:

* Funding agencies can explicitly incentivize platform-crossing collaborations and comparative benchmarks, and allocate dedicated resources for shared infrastructure: error standards, calibration procedures, open reference implementations.
* Conferences can design sessions by _problem_ (“decoherence in many-body systems”) rather than by platform, and normalize sessions on limitations and failures alongside headline results. Mixed-platform panels force cross-reading.
* Journals can require authors to contextualize work across platforms where relevant, not only within their niche, and assign at least one reviewer from a different community when possible. Transparent editorial policies about reviewer selection can reduce suspicion of tribal gatekeeping.
* Prize committees (not only the Nobel) can publish more about their reasoning, including the trade-offs and constraints they faced, and experiment with additional ways of acknowledging broader communities beyond the statutory winner list.
* Universities and departments can adjust evaluation criteria to value infrastructure work, shared tools, and teaching of bias-correction practices as real contributions, making it less risky for individuals to invest in them.

None of these interventions removes conflict or competition. They simply adjust the incentives so that truth-seeking and cross-platform respect are less costly.

#### 6.3 The universal pattern

Although this essay focuses on a specific corner of quantum physics, the underlying pattern is not unique.

Similar dynamics appear in:

* debates between schools in high-energy theory,
* methodological battles in neuroscience,
* replication disputes in psychology,
* and many other places where scientific questions intersect with funding, status, and identity.

Social identity theory and group polarization are general frameworks, not peculiarities of our field. Our minds evolved to maintain coalitions, not to optimize likelihood functions. We are typical social primates trying to do something unusually difficult: seek robustly correct answers in environments where status and resources are unevenly distributed.

Recognizing this is not an excuse. It is a design challenge.

#### 6.4 Closing — The ongoing work

I return, finally, to the three anchors that structured this essay:

*   Technical respect.

    The 1980s experiments honored in the 2025 Nobel Prize represent careful, conceptually important physics. My initial refusal to grant that was a failure of curiosity, not a justified critique.
*   Institutional trust.

    The Nobel system is structurally imperfect, but in this case the Committee’s framing—honoring foundational discovery rather than present-day industrial platforms—is intelligible and defensible, even where one might have chosen differently.
*   Moral responsibility.

    Students and children learn more from how we handle our mistakes than from how we present our successes. If I want them to judge work by content rather than clan, I have to show them how to correct tribal judgments in myself.

I do not expect this essay to fix my bias once and for all. It is not a confession followed by absolution. It is, at best, a snapshot of a calibration process in progress, triggered by a particular event in 2025.

If you recognized something of yourself in these pages—if you have felt the tribal pull when another community wins a prize, secures a grant, or dominates a conference—then perhaps this can be an invitation rather than a verdict.

We will not eliminate bias. But we can design better detectors, and we can make it normal for those detectors to be recalibrated in public.

***

_Special thanks to all my past, current, and future environments._

***

#### References&#x20;

* Nobel Prize in Physics 2025 – Press Release and Summary. NobelPrize.org (2025). “for the discovery of macroscopic quantum mechanical tunnelling and energy quantisation in an electric circuit”.&#x20;
* Scientific Background: The Nobel Prize in Physics 2025. Royal Swedish Academy of Sciences (2025).&#x20;
* Nickerson, R. S. (1998). Confirmation Bias: A Ubiquitous Phenomenon in Many Guises. _Review of General Psychology_, 2(2), 175–220. doi:10.1037/1089-2680.2.2.175&#x20;
* Tajfel, H., & Turner, J. C. (1979). An integrative theory of intergroup conflict. In W. G. Austin & S. Worchel (Eds.), _The Social Psychology of Intergroup Relations_ (pp. 33–47). Monterey, CA: Brooks/Cole.&#x20;
* Tajfel, H., Billig, M. G., Bundy, R. P., & Flament, C. (1971). Social categorization and intergroup behaviour. _European Journal of Social Psychology_, 1(2), 149–178.
* Sunstein, C. R. (2002). The Law of Group Polarization. _Journal of Political Philosophy_, 10(2), 175–195. doi:10.1111/1467-9760.00148&#x20;
* Kahneman, D. (2011). _Thinking, Fast and Slow_. New York: Farrar, Straus and Giroux.
